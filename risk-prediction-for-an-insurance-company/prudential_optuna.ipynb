{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Prudential risk prediction"]},{"cell_type":"markdown","metadata":{},"source":["KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n","\n","KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n","\n","* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n","* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n","\n","You will find instructions below about how to define each variable.\n","\n","Once you're happy with your code, upload your notebook to KATE to check your feedback."]},{"cell_type":"markdown","metadata":{},"source":["We will work with a dataset published by an insurance company which contains anonymised information about their clients.\n","\n","The aim is to predict people's risk profile based on their properties.\n","\n","You will be given a description of the data set and the goal is to develop a prediction model."]},{"cell_type":"markdown","metadata":{},"source":["##  Dataset"]},{"cell_type":"markdown","metadata":{},"source":["The data provided consists of three csv files in the `data/` folder:\n","* `X_train.csv`: the training set\n","* `y_train.csv`: the target for the training set, valued from 1 to 8\n","* `X_test.csv`: the test set that will be evaluated\n","\n","Below we give the description of the data features, some categorical, others numerical. The dataset has been thoroughly anonymized, which makes it extra challenging. \n","\n","Although the risk profile is ordered, we will consider this problem as being a classification problem and the exact category accuracy will be used for evaluating your model. It has low signal, and a 8-classes classification problem, hence accuracy can be quite low."]},{"cell_type":"markdown","metadata":{},"source":["## Get Started\n","\n","Your task is to train a model to predict the target variable. You should save the predictions for the test set in the variable called `y_pred`, which will be evaluated against the ground truth. Below we give you a sample baseline implementation.\n","\n","You are free to use all your modelling skills to get the best possible performance.\n","\n","Good luck!"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset info\n","\n","**Variable descriptions:**\n","- Id - A unique identifier associated with an application.\n","- Product_Info_1-7 - A set of normalized variables relating to the product applied for\n","- Ins_Age - Normalized age of applicant\n","- Ht - Normalized height of applicant\n","- Wt - Normalized weight of applicant\n","- BMI - Normalized BMI of applicant\n","- Employment_Info_1-6 - A set of normalized variables relating to the employment history of the applicant.\n","- InsuredInfo_1-6 - A set of normalized variables providing information about the applicant.\n","- Insurance_History_1-9 - A set of normalized variables relating to the insurance history of the applicant.\n","- Family_Hist_1-5 - A set of normalized variables relating to the family history of the applicant.\n","- Medical_History_1-41 - A set of normalized variables relating to the medical history of the applicant.\n","- Medical_Keyword_1-48 - A set of dummy variables relating to the presence of/absence of a medical keyword being associated with the application.\n","- Response - This is the target variable, an ordinalÂ variable relating to the final decision associated with an application\n","\n","**Categorical (nominal) features:**\n","```\n","Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41\n","```\n","\n","**Continuous features:**\n","```\n","Product_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5\n","```\n","\n","**Discrete features:**\n","```\n","Medical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32\n","Medical_Keyword_1-48 are dummy variables.\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.impute import KNNImputer, SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import classification_report\n","\n","pd.set_option(\"display.max_columns\", 500)\n","\n","import warnings\n","\n","warnings.filterwarnings(category=FutureWarning, action=\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"scrolled":false},"outputs":[],"source":["X_train = pd.read_csv(\"data/X_train.csv\")\n","y_train = pd.read_csv(\"data/y_train.csv\")\n","X_test = pd.read_csv(\"data/X_test.csv\")\n","\n","# categories = [\"Product_Info_1\", \"Product_Info_2\", \"Product_Info_3\",\n","#               \"Product_Info_5\", \"Product_Info_6\", \"Product_Info_7\"]\n","\n","# preprocessor = make_column_transformer((OneHotEncoder(handle_unknown=\"ignore\"), categories))\n","    \n","# model = make_pipeline(preprocessor, DecisionTreeClassifier())\n","\n","# model.fit(X_train, y_train)\n","\n","# y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["((44535, 126), (44535, 1), (14846, 126))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# check how many samples we have\n","X_train.shape, y_train.shape, X_test.shape"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product_Info_1</th>\n","      <th>Product_Info_2</th>\n","      <th>Product_Info_3</th>\n","      <th>Product_Info_4</th>\n","      <th>Product_Info_5</th>\n","      <th>Product_Info_6</th>\n","      <th>Product_Info_7</th>\n","      <th>Ins_Age</th>\n","      <th>Ht</th>\n","      <th>Wt</th>\n","      <th>BMI</th>\n","      <th>Employment_Info_1</th>\n","      <th>Employment_Info_2</th>\n","      <th>Employment_Info_3</th>\n","      <th>Employment_Info_4</th>\n","      <th>Employment_Info_5</th>\n","      <th>Employment_Info_6</th>\n","      <th>InsuredInfo_1</th>\n","      <th>InsuredInfo_2</th>\n","      <th>InsuredInfo_3</th>\n","      <th>InsuredInfo_4</th>\n","      <th>InsuredInfo_5</th>\n","      <th>InsuredInfo_6</th>\n","      <th>InsuredInfo_7</th>\n","      <th>Insurance_History_1</th>\n","      <th>Insurance_History_2</th>\n","      <th>Insurance_History_3</th>\n","      <th>Insurance_History_4</th>\n","      <th>Insurance_History_5</th>\n","      <th>Insurance_History_7</th>\n","      <th>Insurance_History_8</th>\n","      <th>Insurance_History_9</th>\n","      <th>Family_Hist_1</th>\n","      <th>Family_Hist_2</th>\n","      <th>Family_Hist_3</th>\n","      <th>Family_Hist_4</th>\n","      <th>Family_Hist_5</th>\n","      <th>Medical_History_1</th>\n","      <th>Medical_History_2</th>\n","      <th>Medical_History_3</th>\n","      <th>Medical_History_4</th>\n","      <th>Medical_History_5</th>\n","      <th>Medical_History_6</th>\n","      <th>Medical_History_7</th>\n","      <th>Medical_History_8</th>\n","      <th>Medical_History_9</th>\n","      <th>Medical_History_10</th>\n","      <th>Medical_History_11</th>\n","      <th>Medical_History_12</th>\n","      <th>Medical_History_13</th>\n","      <th>Medical_History_14</th>\n","      <th>Medical_History_15</th>\n","      <th>Medical_History_16</th>\n","      <th>Medical_History_17</th>\n","      <th>Medical_History_18</th>\n","      <th>Medical_History_19</th>\n","      <th>Medical_History_20</th>\n","      <th>Medical_History_21</th>\n","      <th>Medical_History_22</th>\n","      <th>Medical_History_23</th>\n","      <th>Medical_History_24</th>\n","      <th>Medical_History_25</th>\n","      <th>Medical_History_26</th>\n","      <th>Medical_History_27</th>\n","      <th>Medical_History_28</th>\n","      <th>Medical_History_29</th>\n","      <th>Medical_History_30</th>\n","      <th>Medical_History_31</th>\n","      <th>Medical_History_32</th>\n","      <th>Medical_History_33</th>\n","      <th>Medical_History_34</th>\n","      <th>Medical_History_35</th>\n","      <th>Medical_History_36</th>\n","      <th>Medical_History_37</th>\n","      <th>Medical_History_38</th>\n","      <th>Medical_History_39</th>\n","      <th>Medical_History_40</th>\n","      <th>Medical_History_41</th>\n","      <th>Medical_Keyword_1</th>\n","      <th>Medical_Keyword_2</th>\n","      <th>Medical_Keyword_3</th>\n","      <th>Medical_Keyword_4</th>\n","      <th>Medical_Keyword_5</th>\n","      <th>Medical_Keyword_6</th>\n","      <th>Medical_Keyword_7</th>\n","      <th>Medical_Keyword_8</th>\n","      <th>Medical_Keyword_9</th>\n","      <th>Medical_Keyword_10</th>\n","      <th>Medical_Keyword_11</th>\n","      <th>Medical_Keyword_12</th>\n","      <th>Medical_Keyword_13</th>\n","      <th>Medical_Keyword_14</th>\n","      <th>Medical_Keyword_15</th>\n","      <th>Medical_Keyword_16</th>\n","      <th>Medical_Keyword_17</th>\n","      <th>Medical_Keyword_18</th>\n","      <th>Medical_Keyword_19</th>\n","      <th>Medical_Keyword_20</th>\n","      <th>Medical_Keyword_21</th>\n","      <th>Medical_Keyword_22</th>\n","      <th>Medical_Keyword_23</th>\n","      <th>Medical_Keyword_24</th>\n","      <th>Medical_Keyword_25</th>\n","      <th>Medical_Keyword_26</th>\n","      <th>Medical_Keyword_27</th>\n","      <th>Medical_Keyword_28</th>\n","      <th>Medical_Keyword_29</th>\n","      <th>Medical_Keyword_30</th>\n","      <th>Medical_Keyword_31</th>\n","      <th>Medical_Keyword_32</th>\n","      <th>Medical_Keyword_33</th>\n","      <th>Medical_Keyword_34</th>\n","      <th>Medical_Keyword_35</th>\n","      <th>Medical_Keyword_36</th>\n","      <th>Medical_Keyword_37</th>\n","      <th>Medical_Keyword_38</th>\n","      <th>Medical_Keyword_39</th>\n","      <th>Medical_Keyword_40</th>\n","      <th>Medical_Keyword_41</th>\n","      <th>Medical_Keyword_42</th>\n","      <th>Medical_Keyword_43</th>\n","      <th>Medical_Keyword_44</th>\n","      <th>Medical_Keyword_45</th>\n","      <th>Medical_Keyword_46</th>\n","      <th>Medical_Keyword_47</th>\n","      <th>Medical_Keyword_48</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>D3</td>\n","      <td>26</td>\n","      <td>0.487179</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.208955</td>\n","      <td>0.745455</td>\n","      <td>0.257322</td>\n","      <td>0.377922</td>\n","      <td>0.072</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.150</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.260870</td>\n","      <td>NaN</td>\n","      <td>0.239437</td>\n","      <td>NaN</td>\n","      <td>12.0</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A2</td>\n","      <td>15</td>\n","      <td>0.076923</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.089552</td>\n","      <td>0.654545</td>\n","      <td>0.246862</td>\n","      <td>0.447639</td>\n","      <td>0.035</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>0.002</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.304348</td>\n","      <td>NaN</td>\n","      <td>0.338028</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>613</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>D4</td>\n","      <td>26</td>\n","      <td>0.230769</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.447761</td>\n","      <td>0.781818</td>\n","      <td>0.320084</td>\n","      <td>0.443418</td>\n","      <td>0.060</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>0.54902</td>\n","      <td>NaN</td>\n","      <td>0.535714</td>\n","      <td>15.0</td>\n","      <td>156</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>D3</td>\n","      <td>26</td>\n","      <td>1.000000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.373134</td>\n","      <td>0.709091</td>\n","      <td>0.269874</td>\n","      <td>0.432872</td>\n","      <td>0.120</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.250</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.006667</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0.565217</td>\n","      <td>NaN</td>\n","      <td>0.464789</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>335</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>D2</td>\n","      <td>29</td>\n","      <td>0.076923</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.328358</td>\n","      <td>0.672727</td>\n","      <td>0.430962</td>\n","      <td>0.764352</td>\n","      <td>0.075</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.003333</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0.492754</td>\n","      <td>NaN</td>\n","      <td>0.408451</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>307</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>12.0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n","0               1             D3              26        0.487179   \n","1               1             A2              15        0.076923   \n","2               1             D4              26        0.230769   \n","3               1             D3              26        1.000000   \n","4               1             D2              29        0.076923   \n","\n","   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n","0               2               3               1  0.208955  0.745455   \n","1               2               3               1  0.089552  0.654545   \n","2               2               3               1  0.447761  0.781818   \n","3               2               1               1  0.373134  0.709091   \n","4               2               1               1  0.328358  0.672727   \n","\n","         Wt       BMI  Employment_Info_1  Employment_Info_2  \\\n","0  0.257322  0.377922              0.072                  9   \n","1  0.246862  0.447639              0.035                  9   \n","2  0.320084  0.443418              0.060                 14   \n","3  0.269874  0.432872              0.120                 14   \n","4  0.430962  0.764352              0.075                  9   \n","\n","   Employment_Info_3  Employment_Info_4  Employment_Info_5  Employment_Info_6  \\\n","0                  1                0.0                  2              0.150   \n","1                  1                0.0                  3              0.002   \n","2                  1                0.0                  2              0.000   \n","3                  1                0.0                  2              0.250   \n","4                  1                0.0                  3                NaN   \n","\n","   InsuredInfo_1  InsuredInfo_2  InsuredInfo_3  InsuredInfo_4  InsuredInfo_5  \\\n","0              1              2              1              3              1   \n","1              1              2              8              3              1   \n","2              2              2              8              3              1   \n","3              2              2              3              3              1   \n","4              1              2              8              3              1   \n","\n","   InsuredInfo_6  InsuredInfo_7  Insurance_History_1  Insurance_History_2  \\\n","0              1              1                    2                    1   \n","1              2              1                    2                    1   \n","2              1              1                    2                    1   \n","3              1              1                    2                    1   \n","4              1              1                    1                    1   \n","\n","   Insurance_History_3  Insurance_History_4  Insurance_History_5  \\\n","0                    1                    3                  NaN   \n","1                    1                    3                  NaN   \n","2                    1                    3                  NaN   \n","3                    3                    1             0.006667   \n","4                    3                    1             0.003333   \n","\n","   Insurance_History_7  Insurance_History_8  Insurance_History_9  \\\n","0                    3                    2                    3   \n","1                    3                    2                    3   \n","2                    3                    2                    3   \n","3                    1                    3                    2   \n","4                    1                    1                    2   \n","\n","   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n","0              3       0.260870            NaN       0.239437            NaN   \n","1              3       0.304348            NaN       0.338028            NaN   \n","2              3            NaN        0.54902            NaN       0.535714   \n","3              3       0.565217            NaN       0.464789            NaN   \n","4              3       0.492754            NaN       0.408451            NaN   \n","\n","   Medical_History_1  Medical_History_2  Medical_History_3  Medical_History_4  \\\n","0               12.0                 16                  2                  1   \n","1                0.0                613                  2                  2   \n","2               15.0                156                  2                  2   \n","3                3.0                335                  2                  2   \n","4                9.0                307                  2                  1   \n","\n","   Medical_History_5  Medical_History_6  Medical_History_7  Medical_History_8  \\\n","0                  1                  3                  2                  2   \n","1                  1                  3                  2                  2   \n","2                  1                  3                  2                  2   \n","3                  1                  3                  2                  2   \n","4                  1                  3                  2                  2   \n","\n","   Medical_History_9  Medical_History_10  Medical_History_11  \\\n","0                  2                 NaN                   3   \n","1                  2                 NaN                   3   \n","2                  2                 NaN                   3   \n","3                  2                 NaN                   3   \n","4                  2                 NaN                   3   \n","\n","   Medical_History_12  Medical_History_13  Medical_History_14  \\\n","0                   2                   3                   3   \n","1                   2                   3                   3   \n","2                   2                   3                   3   \n","3                   2                   3                   3   \n","4                   2                   3                   3   \n","\n","   Medical_History_15  Medical_History_16  Medical_History_17  \\\n","0                 NaN                   1                   3   \n","1                 NaN                   1                   3   \n","2                 NaN                   1                   3   \n","3                 NaN                   1                   3   \n","4                12.0                   1                   3   \n","\n","   Medical_History_18  Medical_History_19  Medical_History_20  \\\n","0                   1                   1                   2   \n","1                   1                   1                   2   \n","2                   1                   1                   2   \n","3                   2                   1                   2   \n","4                   1                   1                   2   \n","\n","   Medical_History_21  Medical_History_22  Medical_History_23  \\\n","0                   1                   2                   3   \n","1                   1                   2                   1   \n","2                   1                   2                   1   \n","3                   1                   2                   1   \n","4                   1                   2                   3   \n","\n","   Medical_History_24  Medical_History_25  Medical_History_26  \\\n","0                 NaN                   1                   3   \n","1                 NaN                   1                   3   \n","2                 NaN                   1                   3   \n","3                 NaN                   1                   3   \n","4                 NaN                   1                   3   \n","\n","   Medical_History_27  Medical_History_28  Medical_History_29  \\\n","0                   3                   1                   3   \n","1                   3                   1                   3   \n","2                   3                   1                   3   \n","3                   3                   1                   3   \n","4                   3                   1                   1   \n","\n","   Medical_History_30  Medical_History_31  Medical_History_32  \\\n","0                   2                   3                 NaN   \n","1                   2                   3                 NaN   \n","2                   2                   3                 NaN   \n","3                   2                   3                 NaN   \n","4                   2                   3                 NaN   \n","\n","   Medical_History_33  Medical_History_34  Medical_History_35  \\\n","0                   3                   3                   1   \n","1                   3                   3                   1   \n","2                   3                   3                   1   \n","3                   3                   3                   1   \n","4                   3                   3                   1   \n","\n","   Medical_History_36  Medical_History_37  Medical_History_38  \\\n","0                   2                   1                   1   \n","1                   2                   2                   1   \n","2                   2                   2                   1   \n","3                   2                   2                   1   \n","4                   2                   2                   1   \n","\n","   Medical_History_39  Medical_History_40  Medical_History_41  \\\n","0                   3                   3                   1   \n","1                   3                   3                   1   \n","2                   3                   3                   1   \n","3                   3                   3                   1   \n","4                   1                   3                   1   \n","\n","   Medical_Keyword_1  Medical_Keyword_2  Medical_Keyword_3  Medical_Keyword_4  \\\n","0                  0                  0                  0                  0   \n","1                  0                  0                  0                  0   \n","2                  0                  0                  0                  0   \n","3                  0                  0                  0                  0   \n","4                  0                  0                  1                  0   \n","\n","   Medical_Keyword_5  Medical_Keyword_6  Medical_Keyword_7  Medical_Keyword_8  \\\n","0                  0                  0                  0                  0   \n","1                  0                  0                  0                  0   \n","2                  0                  0                  0                  0   \n","3                  0                  0                  0                  0   \n","4                  0                  0                  0                  0   \n","\n","   Medical_Keyword_9  Medical_Keyword_10  Medical_Keyword_11  \\\n","0                  0                   0                   1   \n","1                  0                   0                   0   \n","2                  0                   0                   0   \n","3                  0                   0                   0   \n","4                  0                   0                   0   \n","\n","   Medical_Keyword_12  Medical_Keyword_13  Medical_Keyword_14  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_15  Medical_Keyword_16  Medical_Keyword_17  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   1                   0                   0   \n","3                   1                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_18  Medical_Keyword_19  Medical_Keyword_20  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_21  Medical_Keyword_22  Medical_Keyword_23  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_24  Medical_Keyword_25  Medical_Keyword_26  \\\n","0                   0                   0                   0   \n","1                   0                   1                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   1                   0   \n","\n","   Medical_Keyword_27  Medical_Keyword_28  Medical_Keyword_29  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_30  Medical_Keyword_31  Medical_Keyword_32  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_33  Medical_Keyword_34  Medical_Keyword_35  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_36  Medical_Keyword_37  Medical_Keyword_38  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   1                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_39  Medical_Keyword_40  Medical_Keyword_41  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   1                   0   \n","\n","   Medical_Keyword_42  Medical_Keyword_43  Medical_Keyword_44  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_45  Medical_Keyword_46  Medical_Keyword_47  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_48  \n","0                   0  \n","1                   0  \n","2                   0  \n","3                   0  \n","4                   0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["X_train.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["Response\n","8           0.327203\n","6           0.189424\n","7           0.134860\n","2           0.110969\n","1           0.105153\n","5           0.090221\n","4           0.024879\n","3           0.017290\n","dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# check the distribution of the target \n","y_train.value_counts(normalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["## EDA"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 44535 entries, 0 to 44534\n","Data columns (total 126 columns):\n"," #    Column               Non-Null Count  Dtype  \n","---   ------               --------------  -----  \n"," 0    Product_Info_1       44535 non-null  int64  \n"," 1    Product_Info_2       44535 non-null  object \n"," 2    Product_Info_3       44535 non-null  int64  \n"," 3    Product_Info_4       44535 non-null  float64\n"," 4    Product_Info_5       44535 non-null  int64  \n"," 5    Product_Info_6       44535 non-null  int64  \n"," 6    Product_Info_7       44535 non-null  int64  \n"," 7    Ins_Age              44535 non-null  float64\n"," 8    Ht                   44535 non-null  float64\n"," 9    Wt                   44535 non-null  float64\n"," 10   BMI                  44535 non-null  float64\n"," 11   Employment_Info_1    44518 non-null  float64\n"," 12   Employment_Info_2    44535 non-null  int64  \n"," 13   Employment_Info_3    44535 non-null  int64  \n"," 14   Employment_Info_4    39410 non-null  float64\n"," 15   Employment_Info_5    44535 non-null  int64  \n"," 16   Employment_Info_6    36406 non-null  float64\n"," 17   InsuredInfo_1        44535 non-null  int64  \n"," 18   InsuredInfo_2        44535 non-null  int64  \n"," 19   InsuredInfo_3        44535 non-null  int64  \n"," 20   InsuredInfo_4        44535 non-null  int64  \n"," 21   InsuredInfo_5        44535 non-null  int64  \n"," 22   InsuredInfo_6        44535 non-null  int64  \n"," 23   InsuredInfo_7        44535 non-null  int64  \n"," 24   Insurance_History_1  44535 non-null  int64  \n"," 25   Insurance_History_2  44535 non-null  int64  \n"," 26   Insurance_History_3  44535 non-null  int64  \n"," 27   Insurance_History_4  44535 non-null  int64  \n"," 28   Insurance_History_5  25492 non-null  float64\n"," 29   Insurance_History_7  44535 non-null  int64  \n"," 30   Insurance_History_8  44535 non-null  int64  \n"," 31   Insurance_History_9  44535 non-null  int64  \n"," 32   Family_Hist_1        44535 non-null  int64  \n"," 33   Family_Hist_2        23023 non-null  float64\n"," 34   Family_Hist_3        18893 non-null  float64\n"," 35   Family_Hist_4        30098 non-null  float64\n"," 36   Family_Hist_5        13233 non-null  float64\n"," 37   Medical_History_1    37855 non-null  float64\n"," 38   Medical_History_2    44535 non-null  int64  \n"," 39   Medical_History_3    44535 non-null  int64  \n"," 40   Medical_History_4    44535 non-null  int64  \n"," 41   Medical_History_5    44535 non-null  int64  \n"," 42   Medical_History_6    44535 non-null  int64  \n"," 43   Medical_History_7    44535 non-null  int64  \n"," 44   Medical_History_8    44535 non-null  int64  \n"," 45   Medical_History_9    44535 non-null  int64  \n"," 46   Medical_History_10   419 non-null    float64\n"," 47   Medical_History_11   44535 non-null  int64  \n"," 48   Medical_History_12   44535 non-null  int64  \n"," 49   Medical_History_13   44535 non-null  int64  \n"," 50   Medical_History_14   44535 non-null  int64  \n"," 51   Medical_History_15   11152 non-null  float64\n"," 52   Medical_History_16   44535 non-null  int64  \n"," 53   Medical_History_17   44535 non-null  int64  \n"," 54   Medical_History_18   44535 non-null  int64  \n"," 55   Medical_History_19   44535 non-null  int64  \n"," 56   Medical_History_20   44535 non-null  int64  \n"," 57   Medical_History_21   44535 non-null  int64  \n"," 58   Medical_History_22   44535 non-null  int64  \n"," 59   Medical_History_23   44535 non-null  int64  \n"," 60   Medical_History_24   2878 non-null   float64\n"," 61   Medical_History_25   44535 non-null  int64  \n"," 62   Medical_History_26   44535 non-null  int64  \n"," 63   Medical_History_27   44535 non-null  int64  \n"," 64   Medical_History_28   44535 non-null  int64  \n"," 65   Medical_History_29   44535 non-null  int64  \n"," 66   Medical_History_30   44535 non-null  int64  \n"," 67   Medical_History_31   44535 non-null  int64  \n"," 68   Medical_History_32   843 non-null    float64\n"," 69   Medical_History_33   44535 non-null  int64  \n"," 70   Medical_History_34   44535 non-null  int64  \n"," 71   Medical_History_35   44535 non-null  int64  \n"," 72   Medical_History_36   44535 non-null  int64  \n"," 73   Medical_History_37   44535 non-null  int64  \n"," 74   Medical_History_38   44535 non-null  int64  \n"," 75   Medical_History_39   44535 non-null  int64  \n"," 76   Medical_History_40   44535 non-null  int64  \n"," 77   Medical_History_41   44535 non-null  int64  \n"," 78   Medical_Keyword_1    44535 non-null  int64  \n"," 79   Medical_Keyword_2    44535 non-null  int64  \n"," 80   Medical_Keyword_3    44535 non-null  int64  \n"," 81   Medical_Keyword_4    44535 non-null  int64  \n"," 82   Medical_Keyword_5    44535 non-null  int64  \n"," 83   Medical_Keyword_6    44535 non-null  int64  \n"," 84   Medical_Keyword_7    44535 non-null  int64  \n"," 85   Medical_Keyword_8    44535 non-null  int64  \n"," 86   Medical_Keyword_9    44535 non-null  int64  \n"," 87   Medical_Keyword_10   44535 non-null  int64  \n"," 88   Medical_Keyword_11   44535 non-null  int64  \n"," 89   Medical_Keyword_12   44535 non-null  int64  \n"," 90   Medical_Keyword_13   44535 non-null  int64  \n"," 91   Medical_Keyword_14   44535 non-null  int64  \n"," 92   Medical_Keyword_15   44535 non-null  int64  \n"," 93   Medical_Keyword_16   44535 non-null  int64  \n"," 94   Medical_Keyword_17   44535 non-null  int64  \n"," 95   Medical_Keyword_18   44535 non-null  int64  \n"," 96   Medical_Keyword_19   44535 non-null  int64  \n"," 97   Medical_Keyword_20   44535 non-null  int64  \n"," 98   Medical_Keyword_21   44535 non-null  int64  \n"," 99   Medical_Keyword_22   44535 non-null  int64  \n"," 100  Medical_Keyword_23   44535 non-null  int64  \n"," 101  Medical_Keyword_24   44535 non-null  int64  \n"," 102  Medical_Keyword_25   44535 non-null  int64  \n"," 103  Medical_Keyword_26   44535 non-null  int64  \n"," 104  Medical_Keyword_27   44535 non-null  int64  \n"," 105  Medical_Keyword_28   44535 non-null  int64  \n"," 106  Medical_Keyword_29   44535 non-null  int64  \n"," 107  Medical_Keyword_30   44535 non-null  int64  \n"," 108  Medical_Keyword_31   44535 non-null  int64  \n"," 109  Medical_Keyword_32   44535 non-null  int64  \n"," 110  Medical_Keyword_33   44535 non-null  int64  \n"," 111  Medical_Keyword_34   44535 non-null  int64  \n"," 112  Medical_Keyword_35   44535 non-null  int64  \n"," 113  Medical_Keyword_36   44535 non-null  int64  \n"," 114  Medical_Keyword_37   44535 non-null  int64  \n"," 115  Medical_Keyword_38   44535 non-null  int64  \n"," 116  Medical_Keyword_39   44535 non-null  int64  \n"," 117  Medical_Keyword_40   44535 non-null  int64  \n"," 118  Medical_Keyword_41   44535 non-null  int64  \n"," 119  Medical_Keyword_42   44535 non-null  int64  \n"," 120  Medical_Keyword_43   44535 non-null  int64  \n"," 121  Medical_Keyword_44   44535 non-null  int64  \n"," 122  Medical_Keyword_45   44535 non-null  int64  \n"," 123  Medical_Keyword_46   44535 non-null  int64  \n"," 124  Medical_Keyword_47   44535 non-null  int64  \n"," 125  Medical_Keyword_48   44535 non-null  int64  \n","dtypes: float64(18), int64(107), object(1)\n","memory usage: 42.8+ MB\n"]}],"source":["X_train.info(verbose=True, show_counts=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# add target in temporarily for EDA\n","df = X_train.copy()\n","df[\"target\"] = y_train"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product_Info_1</th>\n","      <th>Product_Info_2</th>\n","      <th>Product_Info_3</th>\n","      <th>Product_Info_4</th>\n","      <th>Product_Info_5</th>\n","      <th>Product_Info_6</th>\n","      <th>Product_Info_7</th>\n","      <th>Ins_Age</th>\n","      <th>Ht</th>\n","      <th>Wt</th>\n","      <th>BMI</th>\n","      <th>Employment_Info_1</th>\n","      <th>Employment_Info_2</th>\n","      <th>Employment_Info_3</th>\n","      <th>Employment_Info_4</th>\n","      <th>Employment_Info_5</th>\n","      <th>Employment_Info_6</th>\n","      <th>InsuredInfo_1</th>\n","      <th>InsuredInfo_2</th>\n","      <th>InsuredInfo_3</th>\n","      <th>InsuredInfo_4</th>\n","      <th>InsuredInfo_5</th>\n","      <th>InsuredInfo_6</th>\n","      <th>InsuredInfo_7</th>\n","      <th>Insurance_History_1</th>\n","      <th>Insurance_History_2</th>\n","      <th>Insurance_History_3</th>\n","      <th>Insurance_History_4</th>\n","      <th>Insurance_History_5</th>\n","      <th>Insurance_History_7</th>\n","      <th>Insurance_History_8</th>\n","      <th>Insurance_History_9</th>\n","      <th>Family_Hist_1</th>\n","      <th>Family_Hist_2</th>\n","      <th>Family_Hist_3</th>\n","      <th>Family_Hist_4</th>\n","      <th>Family_Hist_5</th>\n","      <th>Medical_History_1</th>\n","      <th>Medical_History_2</th>\n","      <th>Medical_History_3</th>\n","      <th>Medical_History_4</th>\n","      <th>Medical_History_5</th>\n","      <th>Medical_History_6</th>\n","      <th>Medical_History_7</th>\n","      <th>Medical_History_8</th>\n","      <th>Medical_History_9</th>\n","      <th>Medical_History_10</th>\n","      <th>Medical_History_11</th>\n","      <th>Medical_History_12</th>\n","      <th>Medical_History_13</th>\n","      <th>Medical_History_14</th>\n","      <th>Medical_History_15</th>\n","      <th>Medical_History_16</th>\n","      <th>Medical_History_17</th>\n","      <th>Medical_History_18</th>\n","      <th>Medical_History_19</th>\n","      <th>Medical_History_20</th>\n","      <th>Medical_History_21</th>\n","      <th>Medical_History_22</th>\n","      <th>Medical_History_23</th>\n","      <th>Medical_History_24</th>\n","      <th>Medical_History_25</th>\n","      <th>Medical_History_26</th>\n","      <th>Medical_History_27</th>\n","      <th>Medical_History_28</th>\n","      <th>Medical_History_29</th>\n","      <th>Medical_History_30</th>\n","      <th>Medical_History_31</th>\n","      <th>Medical_History_32</th>\n","      <th>Medical_History_33</th>\n","      <th>Medical_History_34</th>\n","      <th>Medical_History_35</th>\n","      <th>Medical_History_36</th>\n","      <th>Medical_History_37</th>\n","      <th>Medical_History_38</th>\n","      <th>Medical_History_39</th>\n","      <th>Medical_History_40</th>\n","      <th>Medical_History_41</th>\n","      <th>Medical_Keyword_1</th>\n","      <th>Medical_Keyword_2</th>\n","      <th>Medical_Keyword_3</th>\n","      <th>Medical_Keyword_4</th>\n","      <th>Medical_Keyword_5</th>\n","      <th>Medical_Keyword_6</th>\n","      <th>Medical_Keyword_7</th>\n","      <th>Medical_Keyword_8</th>\n","      <th>Medical_Keyword_9</th>\n","      <th>Medical_Keyword_10</th>\n","      <th>Medical_Keyword_11</th>\n","      <th>Medical_Keyword_12</th>\n","      <th>Medical_Keyword_13</th>\n","      <th>Medical_Keyword_14</th>\n","      <th>Medical_Keyword_15</th>\n","      <th>Medical_Keyword_16</th>\n","      <th>Medical_Keyword_17</th>\n","      <th>Medical_Keyword_18</th>\n","      <th>Medical_Keyword_19</th>\n","      <th>Medical_Keyword_20</th>\n","      <th>Medical_Keyword_21</th>\n","      <th>Medical_Keyword_22</th>\n","      <th>Medical_Keyword_23</th>\n","      <th>Medical_Keyword_24</th>\n","      <th>Medical_Keyword_25</th>\n","      <th>Medical_Keyword_26</th>\n","      <th>Medical_Keyword_27</th>\n","      <th>Medical_Keyword_28</th>\n","      <th>Medical_Keyword_29</th>\n","      <th>Medical_Keyword_30</th>\n","      <th>Medical_Keyword_31</th>\n","      <th>Medical_Keyword_32</th>\n","      <th>Medical_Keyword_33</th>\n","      <th>Medical_Keyword_34</th>\n","      <th>Medical_Keyword_35</th>\n","      <th>Medical_Keyword_36</th>\n","      <th>Medical_Keyword_37</th>\n","      <th>Medical_Keyword_38</th>\n","      <th>Medical_Keyword_39</th>\n","      <th>Medical_Keyword_40</th>\n","      <th>Medical_Keyword_41</th>\n","      <th>Medical_Keyword_42</th>\n","      <th>Medical_Keyword_43</th>\n","      <th>Medical_Keyword_44</th>\n","      <th>Medical_Keyword_45</th>\n","      <th>Medical_Keyword_46</th>\n","      <th>Medical_Keyword_47</th>\n","      <th>Medical_Keyword_48</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>D3</td>\n","      <td>26</td>\n","      <td>0.487179</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.208955</td>\n","      <td>0.745455</td>\n","      <td>0.257322</td>\n","      <td>0.377922</td>\n","      <td>0.072</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.150</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.260870</td>\n","      <td>NaN</td>\n","      <td>0.239437</td>\n","      <td>NaN</td>\n","      <td>12.0</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A2</td>\n","      <td>15</td>\n","      <td>0.076923</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.089552</td>\n","      <td>0.654545</td>\n","      <td>0.246862</td>\n","      <td>0.447639</td>\n","      <td>0.035</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>0.002</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.304348</td>\n","      <td>NaN</td>\n","      <td>0.338028</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>613</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>D4</td>\n","      <td>26</td>\n","      <td>0.230769</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.447761</td>\n","      <td>0.781818</td>\n","      <td>0.320084</td>\n","      <td>0.443418</td>\n","      <td>0.060</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>0.54902</td>\n","      <td>NaN</td>\n","      <td>0.535714</td>\n","      <td>15.0</td>\n","      <td>156</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>D3</td>\n","      <td>26</td>\n","      <td>1.000000</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.373134</td>\n","      <td>0.709091</td>\n","      <td>0.269874</td>\n","      <td>0.432872</td>\n","      <td>0.120</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0.250</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.006667</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0.565217</td>\n","      <td>NaN</td>\n","      <td>0.464789</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>335</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>D2</td>\n","      <td>29</td>\n","      <td>0.076923</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.328358</td>\n","      <td>0.672727</td>\n","      <td>0.430962</td>\n","      <td>0.764352</td>\n","      <td>0.075</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.003333</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0.492754</td>\n","      <td>NaN</td>\n","      <td>0.408451</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>307</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>12.0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n","0               1             D3              26        0.487179   \n","1               1             A2              15        0.076923   \n","2               1             D4              26        0.230769   \n","3               1             D3              26        1.000000   \n","4               1             D2              29        0.076923   \n","\n","   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n","0               2               3               1  0.208955  0.745455   \n","1               2               3               1  0.089552  0.654545   \n","2               2               3               1  0.447761  0.781818   \n","3               2               1               1  0.373134  0.709091   \n","4               2               1               1  0.328358  0.672727   \n","\n","         Wt       BMI  Employment_Info_1  Employment_Info_2  \\\n","0  0.257322  0.377922              0.072                  9   \n","1  0.246862  0.447639              0.035                  9   \n","2  0.320084  0.443418              0.060                 14   \n","3  0.269874  0.432872              0.120                 14   \n","4  0.430962  0.764352              0.075                  9   \n","\n","   Employment_Info_3  Employment_Info_4  Employment_Info_5  Employment_Info_6  \\\n","0                  1                0.0                  2              0.150   \n","1                  1                0.0                  3              0.002   \n","2                  1                0.0                  2              0.000   \n","3                  1                0.0                  2              0.250   \n","4                  1                0.0                  3                NaN   \n","\n","   InsuredInfo_1  InsuredInfo_2  InsuredInfo_3  InsuredInfo_4  InsuredInfo_5  \\\n","0              1              2              1              3              1   \n","1              1              2              8              3              1   \n","2              2              2              8              3              1   \n","3              2              2              3              3              1   \n","4              1              2              8              3              1   \n","\n","   InsuredInfo_6  InsuredInfo_7  Insurance_History_1  Insurance_History_2  \\\n","0              1              1                    2                    1   \n","1              2              1                    2                    1   \n","2              1              1                    2                    1   \n","3              1              1                    2                    1   \n","4              1              1                    1                    1   \n","\n","   Insurance_History_3  Insurance_History_4  Insurance_History_5  \\\n","0                    1                    3                  NaN   \n","1                    1                    3                  NaN   \n","2                    1                    3                  NaN   \n","3                    3                    1             0.006667   \n","4                    3                    1             0.003333   \n","\n","   Insurance_History_7  Insurance_History_8  Insurance_History_9  \\\n","0                    3                    2                    3   \n","1                    3                    2                    3   \n","2                    3                    2                    3   \n","3                    1                    3                    2   \n","4                    1                    1                    2   \n","\n","   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n","0              3       0.260870            NaN       0.239437            NaN   \n","1              3       0.304348            NaN       0.338028            NaN   \n","2              3            NaN        0.54902            NaN       0.535714   \n","3              3       0.565217            NaN       0.464789            NaN   \n","4              3       0.492754            NaN       0.408451            NaN   \n","\n","   Medical_History_1  Medical_History_2  Medical_History_3  Medical_History_4  \\\n","0               12.0                 16                  2                  1   \n","1                0.0                613                  2                  2   \n","2               15.0                156                  2                  2   \n","3                3.0                335                  2                  2   \n","4                9.0                307                  2                  1   \n","\n","   Medical_History_5  Medical_History_6  Medical_History_7  Medical_History_8  \\\n","0                  1                  3                  2                  2   \n","1                  1                  3                  2                  2   \n","2                  1                  3                  2                  2   \n","3                  1                  3                  2                  2   \n","4                  1                  3                  2                  2   \n","\n","   Medical_History_9  Medical_History_10  Medical_History_11  \\\n","0                  2                 NaN                   3   \n","1                  2                 NaN                   3   \n","2                  2                 NaN                   3   \n","3                  2                 NaN                   3   \n","4                  2                 NaN                   3   \n","\n","   Medical_History_12  Medical_History_13  Medical_History_14  \\\n","0                   2                   3                   3   \n","1                   2                   3                   3   \n","2                   2                   3                   3   \n","3                   2                   3                   3   \n","4                   2                   3                   3   \n","\n","   Medical_History_15  Medical_History_16  Medical_History_17  \\\n","0                 NaN                   1                   3   \n","1                 NaN                   1                   3   \n","2                 NaN                   1                   3   \n","3                 NaN                   1                   3   \n","4                12.0                   1                   3   \n","\n","   Medical_History_18  Medical_History_19  Medical_History_20  \\\n","0                   1                   1                   2   \n","1                   1                   1                   2   \n","2                   1                   1                   2   \n","3                   2                   1                   2   \n","4                   1                   1                   2   \n","\n","   Medical_History_21  Medical_History_22  Medical_History_23  \\\n","0                   1                   2                   3   \n","1                   1                   2                   1   \n","2                   1                   2                   1   \n","3                   1                   2                   1   \n","4                   1                   2                   3   \n","\n","   Medical_History_24  Medical_History_25  Medical_History_26  \\\n","0                 NaN                   1                   3   \n","1                 NaN                   1                   3   \n","2                 NaN                   1                   3   \n","3                 NaN                   1                   3   \n","4                 NaN                   1                   3   \n","\n","   Medical_History_27  Medical_History_28  Medical_History_29  \\\n","0                   3                   1                   3   \n","1                   3                   1                   3   \n","2                   3                   1                   3   \n","3                   3                   1                   3   \n","4                   3                   1                   1   \n","\n","   Medical_History_30  Medical_History_31  Medical_History_32  \\\n","0                   2                   3                 NaN   \n","1                   2                   3                 NaN   \n","2                   2                   3                 NaN   \n","3                   2                   3                 NaN   \n","4                   2                   3                 NaN   \n","\n","   Medical_History_33  Medical_History_34  Medical_History_35  \\\n","0                   3                   3                   1   \n","1                   3                   3                   1   \n","2                   3                   3                   1   \n","3                   3                   3                   1   \n","4                   3                   3                   1   \n","\n","   Medical_History_36  Medical_History_37  Medical_History_38  \\\n","0                   2                   1                   1   \n","1                   2                   2                   1   \n","2                   2                   2                   1   \n","3                   2                   2                   1   \n","4                   2                   2                   1   \n","\n","   Medical_History_39  Medical_History_40  Medical_History_41  \\\n","0                   3                   3                   1   \n","1                   3                   3                   1   \n","2                   3                   3                   1   \n","3                   3                   3                   1   \n","4                   1                   3                   1   \n","\n","   Medical_Keyword_1  Medical_Keyword_2  Medical_Keyword_3  Medical_Keyword_4  \\\n","0                  0                  0                  0                  0   \n","1                  0                  0                  0                  0   \n","2                  0                  0                  0                  0   \n","3                  0                  0                  0                  0   \n","4                  0                  0                  1                  0   \n","\n","   Medical_Keyword_5  Medical_Keyword_6  Medical_Keyword_7  Medical_Keyword_8  \\\n","0                  0                  0                  0                  0   \n","1                  0                  0                  0                  0   \n","2                  0                  0                  0                  0   \n","3                  0                  0                  0                  0   \n","4                  0                  0                  0                  0   \n","\n","   Medical_Keyword_9  Medical_Keyword_10  Medical_Keyword_11  \\\n","0                  0                   0                   1   \n","1                  0                   0                   0   \n","2                  0                   0                   0   \n","3                  0                   0                   0   \n","4                  0                   0                   0   \n","\n","   Medical_Keyword_12  Medical_Keyword_13  Medical_Keyword_14  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_15  Medical_Keyword_16  Medical_Keyword_17  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   1                   0                   0   \n","3                   1                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_18  Medical_Keyword_19  Medical_Keyword_20  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_21  Medical_Keyword_22  Medical_Keyword_23  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_24  Medical_Keyword_25  Medical_Keyword_26  \\\n","0                   0                   0                   0   \n","1                   0                   1                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   1                   0   \n","\n","   Medical_Keyword_27  Medical_Keyword_28  Medical_Keyword_29  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_30  Medical_Keyword_31  Medical_Keyword_32  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_33  Medical_Keyword_34  Medical_Keyword_35  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_36  Medical_Keyword_37  Medical_Keyword_38  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   1                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_39  Medical_Keyword_40  Medical_Keyword_41  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   1                   0   \n","\n","   Medical_Keyword_42  Medical_Keyword_43  Medical_Keyword_44  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_45  Medical_Keyword_46  Medical_Keyword_47  \\\n","0                   0                   0                   0   \n","1                   0                   0                   0   \n","2                   0                   0                   0   \n","3                   0                   0                   0   \n","4                   0                   0                   0   \n","\n","   Medical_Keyword_48  target  \n","0                   0       6  \n","1                   0       8  \n","2                   0       5  \n","3                   0       8  \n","4                   0       2  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# encode the 'product info 2' column for ease\n","# encoder = OneHotEncoder()\n","# ohe_transformed = encoder.fit_transform(df[\"Employment_Info_2\"].values.reshape(-1,1))\n","\n","# df = pd.concat([df.drop(columns=[\"Product_Info_2\"]), pd.DataFrame(ohe_transformed, columns=encoder.get_feature_names_out())], axis=1)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["Medical_History_10     0.990592\n","Medical_History_32     0.981071\n","Medical_History_24     0.935377\n","Medical_History_15     0.749590\n","Family_Hist_5          0.702863\n","Family_Hist_3          0.575772\n","Family_Hist_2          0.483036\n","Insurance_History_5    0.427596\n","Family_Hist_4          0.324172\n","Employment_Info_6      0.182531\n","Medical_History_1      0.149994\n","Employment_Info_4      0.115078\n","Employment_Info_1      0.000382\n","Medical_Keyword_14     0.000000\n","Medical_Keyword_15     0.000000\n","dtype: float64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# check missing values\n","\n","\"\"\"\n","We'll drop any columns missing more than 75% of their values as they're pretty lost\n","\n","For the remaining columns, we'll group by similar features and then impute based on the mean value\n","\"\"\"\n","\n","missing_values = df.isnull().sum().sort_values(ascending=False).head(15) / df.shape[0]\n","missing_values"]},{"cell_type":"markdown","metadata":{},"source":["## Modelling"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# cleans dataset\n","class DataCleaner(BaseEstimator, TransformerMixin):\n","    def __init__(self) -> None:\n","        pass\n","    \n","    def fit(self, X, y=None):\n","        # collect columns that are missing greater than 75% of their values\n","        missing_values = X.isnull().sum().sort_values(ascending=False).head(15) / X.shape[0]\n","        self.missing_columns = missing_values[missing_values > 0.75].index.to_list()\n","        \n","        # collect columns that are correlated\n","        correlations = X_train.drop(columns=[\"Product_Info_2\"]).corr()\n","        correlations = correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(bool))\n","        self.correlated_columns = [column for column in correlations.columns if any(correlations[column] > 0.9)]\n","        \n","        return self\n","    \n","    def transform(self, X):\n","        X_transformed = X.copy()\n","        \n","        # remove columns that are missing greater than 75% of their values\n","        X_transformed = X_transformed.drop(columns=self.missing_columns)\n","        \n","        # remove correlated columns\n","        X_transformed = X_transformed.drop(columns=self.correlated_columns)\n","        \n","        return X_transformed\n","   \n","# feature engineering \n","class FeatureEngineer(BaseEstimator, TransformerMixin):\n","    def __init__(self) -> None:\n","        pass\n","    \n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X):\n","        X_transformed = X.copy()\n","        \n","        # log + 1 transformation of BMI \n","        X_transformed[\"BMI\"] = np.log1p(X_transformed[\"BMI\"])\n","        \n","        return X_transformed"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# pipelines\n","clean_pipeline = Pipeline(\n","    [\n","        (\"data_cleaner\", DataCleaner()),\n","    ]\n",")\n","\n","object_columns = X_train.select_dtypes(\"object\").columns\n","encoder_ct = ColumnTransformer(\n","    [\n","        (\"encode\", OneHotEncoder(), object_columns)\n","    ],\n","    remainder=\"passthrough\"\n",")\n","\n","transformation_pipeline = Pipeline(\n","    [\n","        (\"clean_pipeline\", clean_pipeline),\n","        (\"feature_engineer\", FeatureEngineer()),\n","        (\"encoder\", encoder_ct),\n","        (\"imputer\", SimpleImputer()),\n","        #(\"pca\", PCA(n_components=5))\n","    ]\n",")\n","\n","# transformation_pipeline"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["pipeline = transformation_pipeline.fit(X_train)\n","transfomred_x_train = pipeline.transform(X_train)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# if y_train.min().values == 1:\n","#     y_train -= 1\n","    \n","# cv = StratifiedKFold(shuffle=True, random_state=68)\n","# for i, (train_index, test_index) in enumerate(cv.split(transfomred_x_train, y_train)):\n","#     x_train, y_train_ = transfomred_x_train[train_index], y_train.values[train_index]\n","#     x_test_, y_test = transfomred_x_train[test_index], y_train.values[test_index]\n","    \n","#     model = XGBClassifier()\n","#     model.fit(x_train, y_train_.reshape(-1,))\n","    \n","#     score = model.score(x_test_, y_test)\n","#     print(score)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# add one as XGB classifiers don't like it when the smallest value isn't 0\n","# y_pred = model.predict(pipeline.transform(X_test)) + 1"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# p = model.predict(x_test_)\n","# print(classification_report(y_test, model.predict(x_test_)))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import StackingClassifier\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","import optuna\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def objective_function(trial):\n","    hyperparams = {\n","        \"rfc__n_estimators\": trial.suggest_int(\"rfc__n_estimators\", 20, 260),\n","        \"rfc__max_depth\": trial.suggest_int(\"rfc__max_depth\", 1, 20),\n","        \n","        \"lr__C\": trial.suggest_float(\"lr__C\", 0, 3),\n","        \"lr__penalty\": trial.suggest_categorical(\"lr_penalty\", [None, \"l2\"]),\n","        \n","        \"rc__alpha\": trial.suggest_float(\"rc__alpha\", 0, 3)\n","    }\n","\n","    outer_cv = StratifiedKFold(shuffle=True, random_state=259)\n","    inner_cv = StratifiedKFold(shuffle=True, random_state=5421)\n","\n","    stacked = StackingClassifier(\n","        [\n","            (\"rfc\", RandomForestClassifier()),\n","            (\"nb\", GaussianNB()),\n","            (\"lr\", LogisticRegression(max_iter=2500)),\n","            (\"rc\", RidgeClassifier())\n","        ],\n","        cv=inner_cv\n","    )\n","    \n","    stacked.set_params(**hyperparams)\n","    \n","    nested_score = cross_val_score(stacked, X=transfomred_x_train[:100], y=y_train.values[:100].reshape(-1,), cv=outer_cv)\n","\n","    return np.mean(nested_score)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-29 21:21:39,297] A new study created in memory with name: no-name-75d6c6f6-3d99-4a21-8982-f8732cba5a03\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-02-29 21:22:07,255] Trial 0 finished with value: 0.23000000000000004 and parameters: {'rfc__n_estimators': 210, 'rfc__max_depth': 6, 'lr__C': 1.9533556936242051, 'lr_penalty': 'l2', 'rc__alpha': 2.7243972279745834}. Best is trial 0 with value: 0.23000000000000004.\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-02-29 21:22:34,590] Trial 1 finished with value: 0.21000000000000002 and parameters: {'rfc__n_estimators': 171, 'rfc__max_depth': 11, 'lr__C': 0.6871246781959973, 'lr_penalty': 'l2', 'rc__alpha': 2.445390929864197}. Best is trial 0 with value: 0.23000000000000004.\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1426: RuntimeWarning: Number of classes in training fold (7) does not match total number of classes (8). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n","  warnings.warn(\n","c:\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n","ABNORMAL_TERMINATION_IN_LNSRCH.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","[I 2024-02-29 21:23:05,257] Trial 2 finished with value: 0.23000000000000004 and parameters: {'rfc__n_estimators': 217, 'rfc__max_depth': 10, 'lr__C': 1.0069447192498147, 'lr_penalty': 'l2', 'rc__alpha': 0.2469167939228678}. Best is trial 0 with value: 0.23000000000000004.\n"]}],"source":["stacked_study = optuna.create_study(direction=\"maximize\")\n","stacked_study.optimize(objective_function, n_trials=3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
